services:
  spark-master:
    image: spark:3.5.4-scala2.12-java11-python3-ubuntu
    container_name: spark-master
    hostname: spark-master
    command: ["/opt/spark/bin/spark-class","org.apache.spark.deploy.master.Master","--host","spark-master","--port","7077","--webui-port","8080"]
    ports: ["7077:7077","8080:8080"]
    environment:
      - SPARK_SUBMIT_OPTS=-Dspark.jars.ivy=/opt/spark/.ivy2
    networks: [lakehouse]
    volumes:
      - ./scala:/work/scala
      - ./data:/work/data
      - ./jars:/work/jars
      - spark-ivy:/opt/spark/.ivy2

  spark-worker:
    image: spark:3.5.4-scala2.12-java11-python3-ubuntu
    container_name: spark-worker
    hostname: spark-worker
    depends_on: [spark-master]
    command: ["/opt/spark/bin/spark-class","org.apache.spark.deploy.worker.Worker","spark://spark-master:7077","--cores","2","--memory","2g","--webui-port","8081"]
    ports: ["8081:8081"]
    environment:
      - SPARK_SUBMIT_OPTS=-Dspark.jars.ivy=/opt/spark/.ivy2
    networks: [lakehouse]
    volumes:
      - ./data:/work/data
      - spark-ivy:/opt/spark/.ivy2

  jupyter:
    image: jupyter/pyspark-notebook:python-3.11
    container_name: lakehouse-jupyter
    depends_on: [spark-master, minio]
    ports: ["8888:8888"]
    environment:
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - MLFLOW_S3_ENDPOINT_URL=${MLFLOW_S3_ENDPOINT_URL}
      - PYSPARK_PYTHON=python
      - PYSPARK_DRIVER_PYTHON=jupyter
      - PYSPARK_DRIVER_PYTHON_OPTS=lab --NotebookApp.token='' --NotebookApp.password=''
    command: >
      bash -lc "pip install --no-cache-dir delta-spark==3.1.0 great_expectations mlflow &&
                start-notebook.sh --NotebookApp.token=''"
    networks: [lakehouse]
    volumes:
      - ./py:/work/py
      - ./data:/work/data
      - ./scripts:/work/scripts 

  minio:
    image: minio/minio:latest
    container_name: minio
    env_file: .env
    command: server /data --console-address ':9001'
    ports: ["9000:9000","9001:9001"]
    volumes:
      - ./minio/data:/data
    networks: [lakehouse]

  minio-setup:
    image: minio/mc:latest
    container_name: minio-setup
    depends_on: [minio]
    env_file: .env
    entrypoint: >
      /bin/sh -c "
      set -e;
      until mc alias set minio http://minio:9000 $${MINIO_ROOT_USER} $${MINIO_ROOT_PASSWORD}; do
        echo 'waiting for MinIO...'; sleep 2;
      done;
      for b in bronze silver gold mlflow; do mc mb -p minio/$$b || true; done;
      mc ls minio
      "
    networks: [lakehouse]

  mlflow:
    image: python:3.11-slim
    container_name: mlflow
    depends_on: [minio]
    env_file: .env
    command: >
      bash -lc "pip install --no-cache-dir mlflow boto3 &&
                mlflow server --backend-store-uri sqlite:///mlruns.db
                             --default-artifact-root s3://mlflow
                             --host 0.0.0.0 --port 5000"
    ports: ["5000:5000"]
    volumes:
      - ./mlflow:/mlflow
    working_dir: /mlflow
    networks: [lakehouse]

  scala-builder:
    image: sbtscala/scala-sbt:eclipse-temurin-jammy-11.0.21_9_1.9.7_2.12.18
    container_name: scala-builder
    profiles: ["build"]
    working_dir: /work
    command: sbt -v clean package
    volumes:
      - ./scala:/work
    networks: [lakehouse]

networks:
  lakehouse:
    driver: bridge

volumes:
  spark-ivy:

